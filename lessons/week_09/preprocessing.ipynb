{"cells":[{"cell_type":"markdown","metadata":{"id":"j4RpK9pawQzP"},"source":["# Your Second Image Classifier: Using CNN to Classify Images\n","# Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"vbuzxq-b90j-"},"source":["The purpose of this dataset is to correctly classify an image as containing a dog, cat, or panda.\n","Containing only 3,000 images, the Animals dataset is meant to be another **introductory** dataset\n","that we can quickly train a CNN model.\n","\n","Let's take the following steps:\n","\n","1. Fetch Data (reuse of the previous project)\n","2. Pre-processing\n","3. Clean data\n","\n","<center><img width=\"900\" src=\"https://drive.google.com/uc?export=view&id=1haMB_Zt6Et9q9sPHxfuR4g3FT5QRXlTI\"></center>\n"]},{"cell_type":"markdown","metadata":{"id":"ApYpc47MFOYi"},"source":["## Step 01: Setup"]},{"cell_type":"markdown","metadata":{"id":"ULBka-lQFJW9"},"source":["Start out by installing the experiment tracking library and setting up your free W&B account:\n","\n","\n","*   **pip install wandb** – Install the W&B library\n","*   **import wandb** – Import the wandb library\n","*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vWnFIWPuFXej","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666655404976,"user_tz":180,"elapsed":9728,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"ccb7280a-8ea4-4f9c-818c-04a85e9e3457"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 26.7 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 72.4 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 55.4 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 78.3 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 55.0 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 63.2 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 60.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 63.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 65.6 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 55.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 65.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 63.4 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 61.0 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 60.8 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install wandb -qU"]},{"cell_type":"markdown","metadata":{"id":"wcrOk6pURp50"},"source":["### Import Packages"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VJaCNlDDRz6d","executionInfo":{"status":"ok","timestamp":1666655414849,"user_tz":180,"elapsed":6121,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"outputs":[],"source":["# import the necessary packages\n","from imutils import paths\n","import logging\n","import os\n","import cv2\n","import numpy as np\n","import joblib\n","import tensorflow as tf\n","import wandb"]},{"cell_type":"code","source":["wandb.login()"],"metadata":{"id":"GaqfBz4Ol3p8","colab":{"base_uri":"https://localhost:8080/","height":108},"executionInfo":{"status":"ok","timestamp":1666655422217,"user_tz":180,"elapsed":6048,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"fe4254e3-823d-4828-ed6e-3a21c7c5dc96"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qkIkAWcL-4x7","executionInfo":{"status":"ok","timestamp":1666655425903,"user_tz":180,"elapsed":274,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"outputs":[],"source":["# configure logging\n","# reference for a logging obj\n","logger = logging.getLogger()\n","\n","# set level of logging\n","logger.setLevel(logging.INFO)\n","\n","# create handlers\n","c_handler = logging.StreamHandler()\n","c_format = logging.Formatter(fmt=\"%(asctime)s %(message)s\",datefmt='%d-%m-%Y %H:%M:%S')\n","c_handler.setFormatter(c_format)\n","\n","# add handler to the logger\n","logger.handlers[0] = c_handler"]},{"cell_type":"markdown","metadata":{"id":"m-XgvGlGx-n_"},"source":["## Step 02: Fetch Data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"KlLArYonw4pJ","executionInfo":{"status":"ok","timestamp":1666655429774,"user_tz":180,"elapsed":270,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","  \"project_name\": \"first_image_classifier\",\n","  \"artifact_name\": \"animals_raw_data:latest\",\n","}"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"r3kCOus2wzbw","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1666655458471,"user_tz":180,"elapsed":26931,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"be161f4a-7762-4d8c-c567-fc3199722c97"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mivanovitch-silva\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221024_235031-y85oy47t</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/ivanovitch-silva/first_image_classifier/runs/y85oy47t\" target=\"_blank\">enchanting-celebration-7</a></strong> to <a href=\"https://wandb.ai/ivanovitch-silva/first_image_classifier\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact animals_raw_data:latest, 187.97MB. 3000 files... \n","\u001b[34m\u001b[1mwandb\u001b[0m:   3000 of 3000 files downloaded.  \n","Done. 0:0:25.1\n","24-10-2022 23:50:58 Path: ./artifacts/animals_raw_data:v0\n"]}],"source":["# open the W&B project created in the Fetch step\n","run = wandb.init(entity=\"ivanovitch-silva\",project=args[\"project_name\"], job_type=\"preprocessing\")\n","\n","# download the raw data from W&B\n","raw_data = run.use_artifact(args[\"artifact_name\"])\n","data_dir = raw_data.download()\n","logger.info(\"Path: {}\".format(data_dir))"]},{"cell_type":"code","source":["run.finish()"],"metadata":{"id":"r-aLVJrYFtSV","colab":{"base_uri":"https://localhost:8080/","height":151,"referenced_widgets":["f505abb562674426bf17051cedf0391a","33ed9f5bf97b49b8a320cd0040f2317f","9d16f4f6e13e426f8ed41d3a30c25c1c","65b2682e1f5f46abb766eef2c4b1f2b7","c70b6595013645248e5e07c65b32a707","a0f35cb7ac6e466098132b0dc619aea4","da957715e89649abacedbc435e1fa5be","f0ba145eeecc4c189b833ae5d6e7ddbc"]},"executionInfo":{"status":"ok","timestamp":1666655465480,"user_tz":180,"elapsed":4241,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"32257edb-a2b2-411b-f027-63451a3d17d7"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f505abb562674426bf17051cedf0391a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">enchanting-celebration-7</strong>: <a href=\"https://wandb.ai/ivanovitch-silva/first_image_classifier/runs/y85oy47t\" target=\"_blank\">https://wandb.ai/ivanovitch-silva/first_image_classifier/runs/y85oy47t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221024_235031-y85oy47t/logs</code>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"z4hRGKj23tJQ"},"source":["## Step 03 - Clean Data"]},{"cell_type":"markdown","source":["### Project Config."],"metadata":{"id":"9RpRG_c2JNjd"}},{"cell_type":"code","source":["data_dir"],"metadata":{"id":"GcZcyjj0GCC8","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1666655510032,"user_tz":180,"elapsed":286,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"92b507d1-3cae-4caf-f094-67205d71ce25"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./artifacts/animals_raw_data:v0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"_rlVvuII53sR","executionInfo":{"status":"ok","timestamp":1666655513869,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","\t\"features\": \"clean_features\",\n","  \"target\": \"labels\",\n","  \"project_name\": \"alexnet\"\n","}"]},{"cell_type":"code","source":["# open the W&B project created in the Fetch step\n","run = wandb.init(entity=\"ivanovitch-silva\",project=args[\"project_name\"], job_type=\"preprocessing\")"],"metadata":{"id":"YvF_qIB5NlKm","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1666655517248,"user_tz":180,"elapsed":1612,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"29fc7493-7869-48d2-9e6a-075551402753"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221024_235155-3arb3u9f</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/ivanovitch-silva/alexnet/runs/3arb3u9f\" target=\"_blank\">bright-wick-1</a></strong> to <a href=\"https://wandb.ai/ivanovitch-silva/alexnet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Loader and Preprocessing Classes"],"metadata":{"id":"O_5dUXUKJVyQ"}},{"cell_type":"markdown","source":["Source code based on **Rosebrock, Adrian. Deep Learning For Computer vision with Python, 2019** [link](https://pyimagesearch.com/deep-learning-computer-vision-python-book/)"],"metadata":{"id":"gciJIGOgDHOg"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"zEeK-4xH69L7","executionInfo":{"status":"ok","timestamp":1666655520195,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"outputs":[],"source":["# \n","# a basic simple preprocessor that resize a image\n","#\n","class SimplePreprocessor:\n","\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n","\t\t# store the target image width, height, and interpolation\n","\t\t# method used when resizing\n","\t\tself.width = width\n","\t\tself.height = height\n","\t\tself.inter = inter\n","\n","\tdef preprocess(self, image):\n","\t\t# resize the image to a fixed size, ignoring the aspect\n","\t\t# ratio\n","\t\treturn cv2.resize(image, (self.width, self.height),interpolation=self.inter)"]},{"cell_type":"code","source":["#\n","# Rearrange the dimension of an image and return a numpy array\n","# Default dimension is (heigh, width, channel)\n","#\n","class ImageToArrayPreprocessor:\n","\tdef __init__(self, dataFormat=None):\n","\t\t# store the image data format\n","\t\tself.dataFormat = dataFormat\n","\n","\tdef preprocess(self, image):\n","\t\t# apply the Keras utility function that correctly rearranges\n","\t\t# the dimensions of the image\n","\t\treturn tf.keras.utils.img_to_array(image, data_format=self.dataFormat)"],"metadata":{"id":"t7lYi1pAIica","executionInfo":{"status":"ok","timestamp":1666655520757,"user_tz":180,"elapsed":3,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"x_YLPvoP7OjX","executionInfo":{"status":"ok","timestamp":1666655522192,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}}},"outputs":[],"source":["# Building an image loader\n","class SimpleDatasetLoader:\n","  def __init__(self, preprocessors=None, logger=None):\n","\t\t# store the image preprocessor\n","    self.preprocessors = preprocessors\n","    self.logger = logger\n","\n","\t\t# if the preprocessors are None, initialize them as an\n","\t\t# empty list\n","    if self.preprocessors is None:\n","      self.preprocessors = []\n","\n","  def load(self, imagePaths, verbose=-1):\n","\t\t# initialize the list of features and labels\n","    data = []\n","    labels = []\n","\n","\t\t# loop over the input images\n","    for (i, imagePath) in enumerate(imagePaths):\n","\t\t\t# load the image and extract the class label assuming\n","\t\t\t# that our path has the following format:\n","\t\t\t# /path/to/dataset/{class}/{image}.jpg\n","\t\t\t# e.g \"img example: ./artifacts/animals_raw_data:v0/dogs/dogs_00892.jpg\"\n","\t\t\t# imagePath.split(os.path.sep)[-2] will return \"dogs\"\n","      image = cv2.imread(imagePath)\n","      label = imagePath.split(os.path.sep)[-2]\n","\n","      # check to see if our preprocessors are not None\n","      if self.preprocessors is not None:\n","\t\t\t\t# loop over the preprocessors and apply each to\n","\t\t\t\t# the image\n","        for p in self.preprocessors:\n","          image = p.preprocess(image)\n","\n","\t\t\t# treat our processed image as a \"feature vector\"\n","\t\t\t# by updating the data list followed by the labels\n","      data.append(image)\n","      labels.append(label)\n","   \n","\t\t\t# show an update every `verbose` images\n","      if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n","        logger.info(\"[INFO] processed {}/{}\".format(i + 1,len(imagePaths)))\n","\n","\t\t# return a tuple of the data and labels\n","    return (np.array(data), np.array(labels))"]},{"cell_type":"markdown","source":["### Cleaning"],"metadata":{"id":"2KmT8j1SMfNq"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"OC8kcWO07wxB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666655551519,"user_tz":180,"elapsed":22293,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"2d5c9b60-a22a-4d9a-ecd2-1a433c984b75"},"outputs":[{"output_type":"stream","name":"stderr","text":["24-10-2022 23:52:09 [INFO] preprocessing images...\n","24-10-2022 23:52:11 [INFO] processed 500/3000\n","24-10-2022 23:52:13 [INFO] processed 1000/3000\n","24-10-2022 23:52:17 [INFO] processed 1500/3000\n","24-10-2022 23:52:22 [INFO] processed 2000/3000\n","24-10-2022 23:52:24 [INFO] processed 2500/3000\n","24-10-2022 23:52:27 [INFO] processed 3000/3000\n","24-10-2022 23:52:31 [INFO] features matrix: 3538.2MB\n","24-10-2022 23:52:31 [INFO] labels vector: 0.1MB\n","24-10-2022 23:52:31 [INFO] features shape: (3000, 227, 227, 3), labels shape: (3000,)\n"]}],"source":["# grab the list of images that we'll be describing\n","logger.info(\"[INFO] preprocessing images...\")\n","imagePaths = list(paths.list_images(data_dir))\n","\n","# initialize the image preprocessors\n","sp = SimplePreprocessor(227, 227)\n","iap = ImageToArrayPreprocessor()\n","\n","# load the dataset from disk then scale the raw pixel intensities\n","# to the range [0, 1]\n","sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n","(data, labels) = sdl.load(imagePaths, verbose=500)\n","data = data.astype(\"float\") / 255.0\n","\n","# show some information on memory consumption of the images\n","logger.info(\"[INFO] features matrix: {:.1f}MB\".format(data.nbytes / (1024 * 1024)))\n","logger.info(\"[INFO] labels vector: {:.1f}MB\".format(labels.nbytes / (1024 * 1024)))\n","logger.info(\"[INFO] features shape: {}, labels shape: {}\".format(data.shape,labels.shape))"]},{"cell_type":"markdown","source":["### Dump the artifacts to disk and upload to W&B"],"metadata":{"id":"yPexHIfcNHm_"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"o9KK4Jii8pJe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666655582892,"user_tz":180,"elapsed":14656,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"a7b4ca8d-3115-414d-8dc8-f862a3d1932d"},"outputs":[{"output_type":"stream","name":"stderr","text":["24-10-2022 23:53:02 Dumping the clean data artifacts to disk\n"]}],"source":["# Save the feature artifacts using joblib\n","joblib.dump(data, args[\"features\"])\n","\n","# Save the target using joblib\n","joblib.dump(labels, args[\"target\"])\n","\n","logger.info(\"Dumping the clean data artifacts to disk\")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"bnnmdpK9BLD2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666655611074,"user_tz":180,"elapsed":25469,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"caadd280-959c-4242-c513-f2ffecbaf2fd"},"outputs":[{"output_type":"stream","name":"stderr","text":["24-10-2022 23:53:05 Logging clean data artifact\n"]},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_artifacts.Artifact at 0x7fe2264eff50>"]},"metadata":{},"execution_count":16}],"source":["# clean data artifact\n","artifact = wandb.Artifact(args[\"features\"],\n","                          type=\"CLEAN_DATA\",\n","                          description=\"A json file representing the clean features data\"\n","                          )\n","\n","logger.info(\"Logging clean data artifact\")\n","artifact.add_file(args[\"features\"])\n","run.log_artifact(artifact)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"2RxuZTgACWVw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666655616809,"user_tz":180,"elapsed":287,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"88fb2ab4-6105-4b90-bfc5-a153fc91e5ec"},"outputs":[{"output_type":"stream","name":"stderr","text":["24-10-2022 23:53:36 Logging clean target artifact\n"]},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_artifacts.Artifact at 0x7fe226495e90>"]},"metadata":{},"execution_count":17}],"source":["# clean label artifact\n","artifact = wandb.Artifact(args[\"target\"],\n","                          type=\"CLEAN_DATA\",\n","                          description=\"A json file representing the clean target\"\n","                          )\n","\n","logger.info(\"Logging clean target artifact\")\n","artifact.add_file(args[\"target\"])\n","run.log_artifact(artifact)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"49Ivx0SQCkhT","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1666655651946,"user_tz":180,"elapsed":26151,"user":{"displayName":"Ivanovitch Silva","userId":"16824293402572065120"}},"outputId":"11db9777-eb73-461e-e55c-6e44e0a40118"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">bright-wick-1</strong>: <a href=\"https://wandb.ai/ivanovitch-silva/alexnet/runs/3arb3u9f\" target=\"_blank\">https://wandb.ai/ivanovitch-silva/alexnet/runs/3arb3u9f</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221024_235155-3arb3u9f/logs</code>"]},"metadata":{}}],"source":["run.finish()"]},{"cell_type":"code","source":[],"metadata":{"id":"CbHlJ8BweU5F"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyPwTjmTTXuYzTNVH7qdzEM8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f505abb562674426bf17051cedf0391a":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_33ed9f5bf97b49b8a320cd0040f2317f","IPY_MODEL_9d16f4f6e13e426f8ed41d3a30c25c1c"],"layout":"IPY_MODEL_65b2682e1f5f46abb766eef2c4b1f2b7"}},"33ed9f5bf97b49b8a320cd0040f2317f":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c70b6595013645248e5e07c65b32a707","placeholder":"​","style":"IPY_MODEL_a0f35cb7ac6e466098132b0dc619aea4","value":"0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\r"}},"9d16f4f6e13e426f8ed41d3a30c25c1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_da957715e89649abacedbc435e1fa5be","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0ba145eeecc4c189b833ae5d6e7ddbc","value":1}},"65b2682e1f5f46abb766eef2c4b1f2b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c70b6595013645248e5e07c65b32a707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0f35cb7ac6e466098132b0dc619aea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da957715e89649abacedbc435e1fa5be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0ba145eeecc4c189b833ae5d6e7ddbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}