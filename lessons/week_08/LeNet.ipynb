{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "fApD1K7W4vgq",
        "9f0aWuT2CbNI",
        "p-sPBwNTDxfD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55GzB8QgaBId"
      },
      "source": [
        "# LeNet-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc70EZluafYi"
      },
      "source": [
        "Perhaps the first widely known and successful application of convolutional neural networks was **LeNet-5**, described by Yann LeCun, et al. in their 1998 paper titled [Gradient-Based Learning Applied to Document Recognition](https://ieeexplore.ieee.org/document/726791). The system was developed for use in a handwritten character recognition problem and demonstrated on the **MNIST standard dataset**, achieving approximately 99.2% classification accuracy (or a 0.8% error rate). The network was then described as the central technique in a broader system referred to as **Graph Transformer Networks**.\n",
        "\n",
        "It is a long paper, and perhaps the best part to focus on is Section II. B. that describes the LeNet-5 architecture. In that section, the paper describes the **network as having seven layers** with input **grayscale images** having the shape **32 x 32**, the size of images in the **MNIST dataset**. \n",
        "\n",
        "> The model proposes a pattern of a convolutional layer followed by an average pooling layer, referred to as a **subsampling layer**. \n",
        "\n",
        "This pattern is repeated two and a half times before the output feature maps are flattened and fed to some fully connected layers for interpretation and a final prediction. A picture of the network architecture is provided in the paper and reproduced below.\n",
        "\n",
        "<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1nqbLzHfqorX80I8upHMWINwPNfrmLW-V\"/>\n",
        "\n",
        "The pattern of blocks of convolutional layers and pooling layers (referred to as **subsampling**) grouped and repeated **remains a typical pattern in designing and using convolutional neural networks today, more than twenty years later**. Interestingly, the architecture uses a small number of filters with a modest size as the first hidden layer, specifically 6 filters, each with 5x5 pixels. After pooling, another convolutional layer has many more filters, again with the same size, precisely 16 filters with 5x5 pixels, again followed by pooling. In the repetition of these two blocks of convolution and pooling layers, the trend increases the number of filters.\n",
        "\n",
        "Compared to modern applications, the number of filters is also small, but **the trend of increasing the number of filters with the depth of the network also remains a common pattern in modern usage of the technique.** The flattening of the feature maps and interpretation and classification of the extracted features by fully connected layers also remains a common pattern today. \n",
        "\n",
        "> In modern terminology, the **final section of the architecture** is often referred to as the **classifier**, whereas the **convolutional and pooling layers** earlier in the model are referred to as the **feature extractor**.\n",
        "\n",
        "We can summarize the key aspects of the architecture relevant in modern models as follows:\n",
        "\n",
        "- Fixed-sized input images.\n",
        "- Group convolutional and pooling layers into blocks.\n",
        "- Repetition of convolutional-pooling blocks in the architecture.\n",
        "- Increase in the number of filters with the depth of the network.\n",
        "- Distinct feature extraction and classifier parts of the architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApYpc47MFOYi"
      },
      "source": [
        "## Step 01: Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULBka-lQFJW9"
      },
      "source": [
        "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
        "\n",
        "\n",
        "*   **pip install wandb** – Install the W&B library\n",
        "*   **import wandb** – Import the wandb library\n",
        "*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWnFIWPuFXej"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a Python package for tracking the carbon emissions produced by various\n",
        "# kinds of computer programs, from straightforward algorithms to deep neural networks.\n",
        "!pip install codecarbon"
      ],
      "metadata": {
        "id": "NBqatao0jyp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import logging\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from codecarbon import EmissionsTracker\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from wandb.keras import WandbCallback\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import wandb\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "eRkPuQEg3_RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "7ee2tdx7Cnfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure logging\n",
        "# reference for a logging obj\n",
        "logger = logging.getLogger()\n",
        "\n",
        "# set level of logging\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# create handlers\n",
        "c_handler = logging.StreamHandler()\n",
        "c_format = logging.Formatter(fmt=\"%(asctime)s %(message)s\",datefmt='%d-%m-%Y %H:%M:%S')\n",
        "c_handler.setFormatter(c_format)\n",
        "\n",
        "# add handler to the logger\n",
        "logger.handlers[0] = c_handler"
      ],
      "metadata": {
        "id": "Xq0zG_132yC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 02: Implementing LeNet-5"
      ],
      "metadata": {
        "id": "fApD1K7W4vgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1RF_HWPSImajab-i1ayFeEOoFON0Ky-28\"/>"
      ],
      "metadata": {
        "id": "mykT4hni5RrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source code based on **Rosebrock, Adrian. Deep Learning For Computer vision with Python, 2019** [link](https://pyimagesearch.com/deep-learning-computer-vision-python-book/)"
      ],
      "metadata": {
        "id": "b0pYGw2LK0Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet:\n",
        "  ''' \n",
        "  # create LeNet-5 model\n",
        "  #\n",
        "  # it is composed of the 8 layers (5 layers considering FC as one layer) \n",
        "  # such as:\n",
        "  #      - 2 convolutional layers\n",
        "  #      - 2 subsampling (avg pooling) layers\n",
        "  #      - 1 flatten layer\n",
        "  #      - 2 fully connected layers\n",
        "  #      - 1 output layer with 10 outputs\n",
        "  '''\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, classes):\n",
        "    # initialize the model\n",
        "    model = Sequential()\n",
        "    inputShape = (height, width, depth)\n",
        "    \n",
        "    # if we are using \"channels first\", update the input shape\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "      inputShape = (depth, height, width)\n",
        "   \n",
        "    # first set of CONV => RELU => POOL layers\n",
        "    model.add(Conv2D(6, (5,5), strides=1, padding='same',\n",
        "                     activation='tanh', input_shape=(28,28,1), )) #C1\n",
        "    model.add(AveragePooling2D()) #S2\n",
        "\n",
        "    # second set of CONV => RELU => POOL layers\n",
        "    model.add(Conv2D(16, (5,5), strides=1, padding='valid',\n",
        "                     activation='tanh')) #C3\n",
        "    model.add(AveragePooling2D()) #S4\n",
        "\n",
        "    # a flatten and two set of FC => RELU layers\n",
        "    model.add(Flatten()) #Flatten\n",
        "    model.add(Dense(120, activation='tanh')) #C5\n",
        "    model.add(Dense(84, activation='tanh')) #F6\n",
        "\n",
        "    # softmax classifier\n",
        "    model.add(Dense(10, activation='softmax')) #Output layer\n",
        "    \n",
        "    # return the constructed network architecture\n",
        "    return model"
      ],
      "metadata": {
        "id": "5Um7gG8YvhPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model object\n",
        "model = LeNet.build(28,28,1,10)\n",
        "\n",
        "# summarize layers\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eP-X_bzU8Q3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 03: LeNet-5 on MNIST"
      ],
      "metadata": {
        "id": "UHbHH9ujABI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch, Preprocessing and Data Segregation"
      ],
      "metadata": {
        "id": "9f0aWuT2CbNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "  \"project_name\": \"lenet-5\"\n",
        "}"
      ],
      "metadata": {
        "id": "GBKy-d7RAqFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the W&B project created in the Fetch step\n",
        "run = wandb.init(entity=\"ivanovitch-silva\",\n",
        "                 project=args[\"project_name\"], \n",
        "                 job_type=\"Train\")"
      ],
      "metadata": {
        "id": "P7RZlEXeAk-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 11MB download may take a second)\n",
        "logger.info(\"[INFO] accessing MNIST...\")\n",
        "((train_x, train_y), (test_x, test_y)) = mnist.load_data()\n",
        "\n",
        "logger.info(\"Train x: {}\".format(train_x.shape))\n",
        "logger.info(\"Train y: {}\".format(train_y.shape))\n",
        "logger.info(\"Test x: {}\".format(test_x.shape))\n",
        "logger.info(\"Test y: {}\".format(test_y.shape))"
      ],
      "metadata": {
        "id": "r-oEe_72ADE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we are using \"channels first\" ordering, then reshape the\n",
        "# design matrix such that the matrix is:\n",
        "# num_samples x depth x rows x columns\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], 1, 28, 28))\n",
        "\ttest_x = test_x.reshape((test_x.shape[0], 1, 28, 28))\n",
        " \n",
        "# otherwise, we are using \"channels last\" ordering, so the design\n",
        "# matrix shape should be: num_samples x rows x columns x depth\n",
        "else:\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], 28, 28, 1))\n",
        "\ttest_x = test_x.reshape((test_x.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "y1R74jjyBP_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"Train x: {}\".format(train_x.shape))\n",
        "logger.info(\"Train y: {}\".format(train_y.shape))\n",
        "logger.info(\"Test x: {}\".format(test_x.shape))\n",
        "logger.info(\"Test y: {}\".format(test_y.shape))"
      ],
      "metadata": {
        "id": "N8_HHtVNB-99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale data to the range of [0, 1]\n",
        "train_x = train_x.astype(\"float32\") / 255.0\n",
        "test_x = test_x.astype(\"float32\") / 255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "train_y = lb.fit_transform(train_y)\n",
        "test_y = lb.transform(test_y)"
      ],
      "metadata": {
        "id": "881MdBT4CDCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "urEHaMh7CUDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create codecarbon tracker\n",
        "# codecarbon is too much verbose, change the log level for more info\n",
        "tracker = EmissionsTracker(log_level=\"critical\")\n",
        "tracker.start()\n",
        "\n",
        "# initialize the optimizer and model\n",
        "logger.info(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate=0.01)\n",
        "model = LeNet.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# train the network\n",
        "logger.info(\"[INFO] training network...\")\n",
        "history = model.fit(train_x, train_y,\n",
        "              validation_data=(test_x, test_y),\n",
        "              batch_size=32,\n",
        "              epochs=20, \n",
        "              verbose=0,\n",
        "              callbacks=[wandb.keras.WandbCallback(save_model=False,\n",
        "                                                   compute_flops=True)])\n",
        "\n",
        "# get co2 emissions from tracker\n",
        "# \"CO2 emission (in Kg)\"\n",
        "emissions = tracker.stop()"
      ],
      "metadata": {
        "id": "N8CP0u4uCikx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics"
      ],
      "metadata": {
        "id": "p-sPBwNTDxfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "\n",
        "ax.plot(np.arange(0, 20), history.history[\"loss\"], label=\"train_loss\",linestyle='--')\n",
        "ax.plot(np.arange(0, 20), history.history[\"val_loss\"], label=\"val_loss\",linestyle='--')\n",
        "ax.plot(np.arange(0, 20), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "ax.plot(np.arange(0, 20), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "ax.set_title(\"Training Loss and Accuracy\")\n",
        "ax.set_xlabel(\"Epoch #\")\n",
        "ax.set_ylabel(\"Loss/Accuracy\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IxJLUUHbF4Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] {} kWh of electricity used since the begining\".format(tracker.final_emissions_data.energy_consumed))\n",
        "print(\"[INFO] Energy consumed for RAM: {} kWh\".format(tracker.final_emissions_data.ram_energy))\n",
        "print(\"[INFO] Energy consumed for all GPU: {} kWh\".format(tracker.final_emissions_data.gpu_energy))\n",
        "print(\"[INFO] Energy consumed for all CPU: {} kWh\".format(tracker.final_emissions_data.cpu_energy))\n",
        "print(\"[INFO] CO2 emission {}(in Kg)\".format(tracker.final_emissions_data.emissions))"
      ],
      "metadata": {
        "id": "5Ta3SUAcF7-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(test_x, batch_size=32)\n",
        "print(classification_report(test_y.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1),\n",
        "                            target_names=[str(i) for i in lb.classes_]))"
      ],
      "metadata": {
        "id": "cny66Cg6GZcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_confusion_matrix, ax = plt.subplots(1,1,figsize=(7,4))\n",
        "ConfusionMatrixDisplay(confusion_matrix(predictions.argmax(axis=1),\n",
        "                                        test_y.argmax(axis=1)),\n",
        "                       display_labels=lb.classes_).plot(values_format=\".0f\",ax=ax)\n",
        "\n",
        "ax.set_xlabel(\"True Label\")\n",
        "ax.set_ylabel(\"Predicted Label\")\n",
        "ax.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "USpEF3HXGdh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading figures\n",
        "logger.info(\"Uploading figures\")\n",
        "run.log(\n",
        "    {\n",
        "        \"confusion_matrix\": wandb.Image(fig_confusion_matrix),\n",
        "        # \"other_figure\": wandb.Image(other_fig)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "ptukM077HdGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "logger.info(\"Validation Evaluation metrics\")\n",
        "fbeta = fbeta_score(test_y.argmax(axis=1), \n",
        "                    predictions.argmax(axis=1), \n",
        "                    beta=1, zero_division=1,average='weighted')\n",
        "precision = precision_score(test_y.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1),\n",
        "                            zero_division=1,average='weighted')\n",
        "recall = recall_score(test_y.argmax(axis=1),\n",
        "                      predictions.argmax(axis=1),\n",
        "                      zero_division=1,average='weighted')\n",
        "acc = accuracy_score(test_y.argmax(axis=1),\n",
        "                     predictions.argmax(axis=1))\n",
        "\n",
        "logger.info(\"Validation Accuracy: {}\".format(acc))\n",
        "logger.info(\"Validation Precision: {}\".format(precision))\n",
        "logger.info(\"Validation Recall: {}\".format(recall))\n",
        "logger.info(\"Validation F1: {}\".format(fbeta))\n",
        "\n",
        "run.summary[\"Acc\"] = acc\n",
        "run.summary[\"Precision\"] = precision\n",
        "run.summary[\"Recall\"] = recall\n",
        "run.summary[\"F1\"] = fbeta\n",
        "# number of parameters\n",
        "run.summary[\"Count_Params\"] = model.count_params()\n",
        "# energy unit is kWh\n",
        "run.summary[\"Energy_Consumed\"] = tracker.final_emissions_data.energy_consumed\n",
        "run.summary[\"Energy_RAM\"] = tracker.final_emissions_data.ram_energy\n",
        "run.summary[\"Energy_GPU\"] = tracker.final_emissions_data.gpu_energy\n",
        "run.summary[\"Energy_CPU\"] = tracker.final_emissions_data.cpu_energy\n",
        "# kg\n",
        "run.summary[\"CO2_Emissions\"] = tracker.final_emissions_data.emissions"
      ],
      "metadata": {
        "id": "N1cGMUtdHi-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "KAuk7CyIWQ5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElCu4byeuZjo"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blctuqAA-5G5"
      },
      "source": [
        "According to [Goodfellow et al.](https://www.deeplearningbook.org/), regularization is\n",
        "\n",
        "> “(...) any modification we make to a learning algorithm that is intended to reduce its generalization error, but not its training error”\n",
        "\n",
        "In short, regularization seeks to reduce our testing error perhaps at the expense of increasing training error slightly.\n",
        "\n",
        "We’ve already looked at different forms of regularization in the first part of this course; however, these were parameterized forms of regularization, requiring us to update our loss/update\n",
        "function. In fact, there exist other types of regularization that either:\n",
        "\n",
        "1. Modify the network architecture itself.\n",
        "2. Augment the data passed into the network for training.\n",
        "\n",
        "**Dropout** is a great example of modifying a network architecture by achieving greater generalizability. Here we insert a layer that randomly disconnects nodes from the previous layer to the next layer, thereby ensuring that no single node is responsible for learning how to represent a given class.\n",
        "\n",
        "In this section we’ll be discussing another type of regularization called **data augmentation**. This method purposely perturbs training examples, changing their appearance slightly, before passing them into the network for training. The end result is that a network consistently sees “new” training data points generated from the original training data, partially alleviating the need for us to gather more training data (though in general, gathering more training data will rarely hurt your algorithm).\n",
        "\n",
        "**Data augmentation** encompasses a wide range of techniques used to generate new training samples from the original ones by applying random jitters and perturbations such that the classes labels are\n",
        "not changed. \n",
        "\n",
        "> Our goal when applying **data augmentation** is to increase the generalizability of the model. \n",
        "\n",
        "Given that our network is constantly seeing new, slightly modified versions of the input data points, it’s able to learn more robust features. \n",
        "\n",
        "> At testing time, we do not apply data augmentation\n",
        "and evaluate our trained network – in most cases, you’ll see an increase in testing accuracy, perhaps at the expense at a slight dip in training accuracy.\n",
        "\n",
        "<center><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1PWNBYi_ziF8YnCCd25vnmsf9nxq-KsGH\"></center><center><b>Left</b>: A sample of 250 data points that follow a normal distribution exactly. <b>Right</b>: Adding a small amount of random “jitter” to the distribution. This type of data augmentation can\n",
        "increase the generalizability of our networks.</center>\n",
        "\n",
        "\n",
        "Let’s consider the Figure above (**left**) of a normal distribution with zero mean and unit variance. Training a machine learning model on this data may result in us modeling the distribution exactly –\n",
        "however, in real-world applications, data rarely follows such a neat distribution.\n",
        "\n",
        "Instead, to increase the generalizability of our classifier, we may first randomly jitter points along the distribution by adding some values e drawn from a random distribution (**right**). Our plot\n",
        "still follows an **approximately normal distribution**, but it’s not a perfect distribution as on the left. A model trained on this data is more likely to generalize to example data points not included in the\n",
        "training set.\n",
        "  **In the context of computer vision, data augmentation lends itself naturally**. For example, we can obtain additional training data from the original images by apply simple geometric transforms such as random:\n",
        "\n",
        "1. Translations\n",
        "2. Rotations\n",
        "3. Changes in scale\n",
        "4. Shearing\n",
        "5. Horizontal (and in some cases, vertical) flips\n",
        "\n",
        "Applying a (small) amount of these transformations to an input image will change its appearance slightly, but it does not change the class label – thereby making data augmentation a very natural, easy method to apply to deep learning for computer vision tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch, Preprocessing and Data Segregation"
      ],
      "metadata": {
        "id": "S91_OWOpC22I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "  \"project_name\": \"lenet-5\"\n",
        "}"
      ],
      "metadata": {
        "id": "Ky5KhbTlbJui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the W&B project created in the Fetch step\n",
        "run = wandb.init(entity=\"ivanovitch-silva\",\n",
        "                 project=args[\"project_name\"], \n",
        "                 job_type=\"Train\")"
      ],
      "metadata": {
        "id": "oYUEe0d9bJuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 11MB download may take a second)\n",
        "logger.info(\"[INFO] accessing MNIST...\")\n",
        "((train_x, train_y), (test_x, test_y)) = mnist.load_data()\n",
        "\n",
        "# if we are using \"channels first\" ordering, then reshape the\n",
        "# design matrix such that the matrix is:\n",
        "# num_samples x depth x rows x columns\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], 1, 28, 28))\n",
        "\ttest_x = test_x.reshape((test_x.shape[0], 1, 28, 28))\n",
        " \n",
        "# otherwise, we are using \"channels last\" ordering, so the design\n",
        "# matrix shape should be: num_samples x rows x columns x depth\n",
        "else:\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], 28, 28, 1))\n",
        "\ttest_x = test_x.reshape((test_x.shape[0], 28, 28, 1))\n",
        "\n",
        "logger.info(\"Train x: {}\".format(train_x.shape))\n",
        "logger.info(\"Train y: {}\".format(train_y.shape))\n",
        "logger.info(\"Test x: {}\".format(test_x.shape))\n",
        "logger.info(\"Test y: {}\".format(test_y.shape))"
      ],
      "metadata": {
        "id": "xOxATYHUbJuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpa4fRxmuweP"
      },
      "source": [
        "# visualize 18 numbers\n",
        "def show_image(train_image, label, index):\n",
        "    plt.subplot(3, 6, index+1)\n",
        "    plt.imshow(tf.squeeze(train_image), cmap=plt.cm.gray)\n",
        "    plt.title(label)\n",
        "    plt.grid(b=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m43Dq3WowsCk"
      },
      "source": [
        "# visualize the first 18 numbers\n",
        "plt.figure(figsize=(12, 8))\n",
        "for index in range(18):\n",
        "    label = train_y[index]\n",
        "    image_pixels = train_x[index,:,:,:]\n",
        "    show_image(image_pixels, label, index)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWaYGtKGx4RO"
      },
      "source": [
        "# construct the image generator for data augmentation then\n",
        "# initialize the total number of images generated thus far\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "                         horizontal_flip=False, fill_mode=\"nearest\")\n",
        "total = 0\n",
        "image = train_x[10:11,:,:,:]\n",
        "\n",
        "# construct the actual Python generator\n",
        "print(\"[INFO] generating images...\")\n",
        "imageGen = aug.flow(image, batch_size=1)\n",
        "\n",
        "# create a figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# loop over examples from our image data augmentation generator\n",
        "for img in imageGen:\n",
        "\n",
        "  show_image(img, train_y[10], total)\n",
        "\n",
        "  # increment our counter\n",
        "  total += 1\n",
        "\n",
        "  # if we have reached 10 examples, break from the loop\n",
        "  if total == 18:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale data to the range of [0, 1]\n",
        "train_x = train_x.astype(\"float32\") / 255.0\n",
        "test_x = test_x.astype(\"float32\") / 255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "train_y = lb.fit_transform(train_y)\n",
        "test_y = lb.transform(test_y)"
      ],
      "metadata": {
        "id": "2IjzPziGAFfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "rU6SzSgWDAI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create codecarbon tracker\n",
        "# codecarbon is too much verbose, change the log level for more info\n",
        "tracker = EmissionsTracker(log_level=\"critical\")\n",
        "tracker.start()\n",
        "\n",
        "# initialize the optimizer and model\n",
        "logger.info(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate=0.01)\n",
        "model = LeNet.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# construct the image generator for data augmentation then\n",
        "# initialize the total number of images generated thus far\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, shear_range=0.2, \n",
        "                         zoom_range=0.2,\n",
        "                         horizontal_flip=False, fill_mode=\"nearest\")\n",
        "\n",
        "# train the network\n",
        "logger.info(\"[INFO] training network...\")\n",
        "history = model.fit(aug.flow(train_x, train_y, batch_size=32),\n",
        "                    validation_data=(test_x, test_y),\n",
        "                    epochs=20, \n",
        "                    verbose=0,\n",
        "                    callbacks=[wandb.keras.WandbCallback(save_model=False,\n",
        "                                                         compute_flops=True)])\n",
        "\n",
        "# get co2 emissions from tracker\n",
        "# \"CO2 emission (in Kg)\"\n",
        "emissions = tracker.stop()"
      ],
      "metadata": {
        "id": "HBQWpLHDcuCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics"
      ],
      "metadata": {
        "id": "VEaazfD7DHEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "\n",
        "ax.plot(np.arange(0, 20), history.history[\"loss\"], label=\"train_loss\",linestyle='--')\n",
        "ax.plot(np.arange(0, 20), history.history[\"val_loss\"], label=\"val_loss\",linestyle='--')\n",
        "ax.plot(np.arange(0, 20), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "ax.plot(np.arange(0, 20), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "ax.set_title(\"Training Loss and Accuracy\")\n",
        "ax.set_xlabel(\"Epoch #\")\n",
        "ax.set_ylabel(\"Loss/Accuracy\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8N-KRJhODHEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] {} kWh of electricity used since the begining\".format(tracker.final_emissions_data.energy_consumed))\n",
        "print(\"[INFO] Energy consumed for RAM: {} kWh\".format(tracker.final_emissions_data.ram_energy))\n",
        "print(\"[INFO] Energy consumed for all GPU: {} kWh\".format(tracker.final_emissions_data.gpu_energy))\n",
        "print(\"[INFO] Energy consumed for all CPU: {} kWh\".format(tracker.final_emissions_data.cpu_energy))\n",
        "print(\"[INFO] CO2 emission {}(in Kg)\".format(tracker.final_emissions_data.emissions))"
      ],
      "metadata": {
        "id": "q5i5RRlDDHEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(test_x, batch_size=32)\n",
        "print(classification_report(test_y.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1),\n",
        "                            target_names=[str(i) for i in lb.classes_]))"
      ],
      "metadata": {
        "id": "j5mCbJqPDHEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_confusion_matrix, ax = plt.subplots(1,1,figsize=(7,4))\n",
        "ConfusionMatrixDisplay(confusion_matrix(predictions.argmax(axis=1),\n",
        "                                        test_y.argmax(axis=1)),\n",
        "                       display_labels=lb.classes_).plot(values_format=\".0f\",ax=ax)\n",
        "\n",
        "ax.set_xlabel(\"True Label\")\n",
        "ax.set_ylabel(\"Predicted Label\")\n",
        "ax.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kHdg7-4GDHEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading figures\n",
        "logger.info(\"Uploading figures\")\n",
        "run.log(\n",
        "    {\n",
        "        \"confusion_matrix\": wandb.Image(fig_confusion_matrix),\n",
        "        # \"other_figure\": wandb.Image(other_fig)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "IywiFuGhDHEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "logger.info(\"Validation Evaluation metrics\")\n",
        "fbeta = fbeta_score(test_y.argmax(axis=1), \n",
        "                    predictions.argmax(axis=1), \n",
        "                    beta=1, zero_division=1,average='weighted')\n",
        "precision = precision_score(test_y.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1),\n",
        "                            zero_division=1,average='weighted')\n",
        "recall = recall_score(test_y.argmax(axis=1),\n",
        "                      predictions.argmax(axis=1),\n",
        "                      zero_division=1,average='weighted')\n",
        "acc = accuracy_score(test_y.argmax(axis=1),\n",
        "                     predictions.argmax(axis=1))\n",
        "\n",
        "logger.info(\"Validation Accuracy: {}\".format(acc))\n",
        "logger.info(\"Validation Precision: {}\".format(precision))\n",
        "logger.info(\"Validation Recall: {}\".format(recall))\n",
        "logger.info(\"Validation F1: {}\".format(fbeta))\n",
        "\n",
        "run.summary[\"Acc\"] = acc\n",
        "run.summary[\"Precision\"] = precision\n",
        "run.summary[\"Recall\"] = recall\n",
        "run.summary[\"F1\"] = fbeta\n",
        "# number of parameters\n",
        "run.summary[\"Count_Params\"] = model.count_params()\n",
        "# energy unit is kWh\n",
        "run.summary[\"Energy_Consumed\"] = tracker.final_emissions_data.energy_consumed\n",
        "run.summary[\"Energy_RAM\"] = tracker.final_emissions_data.ram_energy\n",
        "run.summary[\"Energy_GPU\"] = tracker.final_emissions_data.gpu_energy\n",
        "run.summary[\"Energy_CPU\"] = tracker.final_emissions_data.cpu_energy\n",
        "# kg\n",
        "run.summary[\"CO2_Emissions\"] = tracker.final_emissions_data.emissions"
      ],
      "metadata": {
        "id": "WQtxXl8SDHEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "umU3fBfZDHEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zfoqpWeXUd"
      },
      "source": [
        "# Extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kVRLuFxeZkx"
      },
      "source": [
        "This section lists some ideas for extending that you may wish to explore.\n",
        "\n",
        "- **Batch normalization**. Implement BN technique after the CONV Layer review the final result.\n",
        "- **Dropout**. Analyze the use of regularization based on dropout technique and placed with different intensity after the Pooling layer.\n",
        "- **Other activation functions**. Investigate change the activation function to relu and compare the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing IvanNet"
      ],
      "metadata": {
        "id": "vMuxhhRftSXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1zi4EZQdcDtUqp_bA8qaiE6etd-N0NJPP\"/>"
      ],
      "metadata": {
        "id": "5sKZsw-rtSXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source code based on **Rosebrock, Adrian. Deep Learning For Computer vision with Python, 2019** [link](https://pyimagesearch.com/deep-learning-computer-vision-python-book/)"
      ],
      "metadata": {
        "id": "05smmCnhtSXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IvaNet:\n",
        "  ''' \n",
        "  # create IvanNet-5 model\n",
        "  #\n",
        "  # it is composed of the 8 layers (5 layers considering FC as one layer) \n",
        "  # such as:\n",
        "  #      - 2 convolutional layers\n",
        "  #      - 2 subsampling (avg pooling) layers\n",
        "  #      - 1 flatten layer\n",
        "  #      - 2 fully connected layers\n",
        "  #      - 1 output layer with 10 outputs\n",
        "  #      - 2 batchnormalization layers\n",
        "  #      - 4 dropout layers\n",
        "  '''\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, classes):\n",
        "    # initialize the model\n",
        "    model = Sequential()\n",
        "    inputShape = (height, width, depth)\n",
        "    \n",
        "    # if we are using \"channels first\", update the input shape\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "      inputShape = (depth, height, width)\n",
        "   \n",
        "    # first set of CONV => RELU => POOL layers\n",
        "    model.add(Conv2D(6, (5,5), strides=1, padding='same',\n",
        "                     activation='tanh', input_shape=(28,28,1), )) #C1\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(AveragePooling2D()) #S2\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # second set of CONV => RELU => POOL layers\n",
        "    model.add(Conv2D(16, (5,5), strides=1, padding='valid',\n",
        "                     activation='tanh')) #C3\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(AveragePooling2D()) #S4\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # a flatten and two set of FC => RELU layers\n",
        "    model.add(Flatten()) #Flatten\n",
        "    model.add(Dense(120, activation='tanh')) #C5\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(84, activation='tanh')) #F6\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # softmax classifier\n",
        "    model.add(Dense(10, activation='softmax')) #Output layer\n",
        "    \n",
        "    # return the constructed network architecture\n",
        "    return model"
      ],
      "metadata": {
        "id": "rXElSi_FtSXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model object\n",
        "model = IvaNet.build(28,28,1,10)\n",
        "\n",
        "# summarize layers\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-uE5x6MYtSXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch, Preprocessing and Data Segregation"
      ],
      "metadata": {
        "id": "gytVWLAXxrbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "  \"project_name\": \"lenet-5\"\n",
        "}"
      ],
      "metadata": {
        "id": "mo4odprsxrbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the W&B project created in the Fetch step\n",
        "run = wandb.init(entity=\"ivanovitch-silva\",\n",
        "                 project=args[\"project_name\"], \n",
        "                 job_type=\"Train\")"
      ],
      "metadata": {
        "id": "tyRQJHBnxrbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 11MB download may take a second)\n",
        "logger.info(\"[INFO] accessing MNIST...\")\n",
        "((train_x, train_y), (test_x, test_y)) = mnist.load_data()\n",
        "\n",
        "logger.info(\"Train x: {}\".format(train_x.shape))\n",
        "logger.info(\"Train y: {}\".format(train_y.shape))\n",
        "logger.info(\"Test x: {}\".format(test_x.shape))\n",
        "logger.info(\"Test y: {}\".format(test_y.shape))"
      ],
      "metadata": {
        "id": "CiqyrhDYxrbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we are using \"channels first\" ordering, then reshape the\n",
        "# design matrix such that the matrix is:\n",
        "# num_samples x depth x rows x columns\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], 1, 28, 28))\n",
        "\ttest_x = test_x.reshape((test_x.shape[0], 1, 28, 28))\n",
        " \n",
        "# otherwise, we are using \"channels last\" ordering, so the design\n",
        "# matrix shape should be: num_samples x rows x columns x depth\n",
        "else:\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], 28, 28, 1))\n",
        "\ttest_x = test_x.reshape((test_x.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "FvPpKQBuxrbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"Train x: {}\".format(train_x.shape))\n",
        "logger.info(\"Train y: {}\".format(train_y.shape))\n",
        "logger.info(\"Test x: {}\".format(test_x.shape))\n",
        "logger.info(\"Test y: {}\".format(test_y.shape))"
      ],
      "metadata": {
        "id": "4kjHXCNcxrbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale data to the range of [0, 1]\n",
        "train_x = train_x.astype(\"float32\") / 255.0\n",
        "test_x = test_x.astype(\"float32\") / 255.0\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "train_y = lb.fit_transform(train_y)\n",
        "test_y = lb.transform(test_y)"
      ],
      "metadata": {
        "id": "UCG3TKW-xrbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "JjGj4DHvyDoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create codecarbon tracker\n",
        "# codecarbon is too much verbose, change the log level for more info\n",
        "tracker = EmissionsTracker(log_level=\"critical\")\n",
        "tracker.start()\n",
        "\n",
        "# initialize the optimizer and model\n",
        "logger.info(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate=0.01)\n",
        "model = IvaNet.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# train the network\n",
        "logger.info(\"[INFO] training network...\")\n",
        "history = model.fit(train_x, train_y,\n",
        "              validation_data=(test_x, test_y),\n",
        "              batch_size=32,\n",
        "              epochs=20, \n",
        "              verbose=0,\n",
        "              callbacks=[wandb.keras.WandbCallback(save_model=False,\n",
        "                                                   compute_flops=True)])\n",
        "\n",
        "# get co2 emissions from tracker\n",
        "# \"CO2 emission (in Kg)\"\n",
        "emissions = tracker.stop()"
      ],
      "metadata": {
        "id": "rAfI82NRyDor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics"
      ],
      "metadata": {
        "id": "R2jc7JR8y6Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "\n",
        "ax.plot(np.arange(0, 20), history.history[\"loss\"], label=\"train_loss\",linestyle='--')\n",
        "ax.plot(np.arange(0, 20), history.history[\"val_loss\"], label=\"val_loss\",linestyle='--')\n",
        "ax.plot(np.arange(0, 20), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "ax.plot(np.arange(0, 20), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "ax.set_title(\"Training Loss and Accuracy\")\n",
        "ax.set_xlabel(\"Epoch #\")\n",
        "ax.set_ylabel(\"Loss/Accuracy\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0GBCOQwty6Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] {} kWh of electricity used since the begining\".format(tracker.final_emissions_data.energy_consumed))\n",
        "print(\"[INFO] Energy consumed for RAM: {} kWh\".format(tracker.final_emissions_data.ram_energy))\n",
        "print(\"[INFO] Energy consumed for all GPU: {} kWh\".format(tracker.final_emissions_data.gpu_energy))\n",
        "print(\"[INFO] Energy consumed for all CPU: {} kWh\".format(tracker.final_emissions_data.cpu_energy))\n",
        "print(\"[INFO] CO2 emission {}(in Kg)\".format(tracker.final_emissions_data.emissions))"
      ],
      "metadata": {
        "id": "sXte_DZWy6Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(test_x, batch_size=32)\n",
        "print(classification_report(test_y.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1),\n",
        "                            target_names=[str(i) for i in lb.classes_]))"
      ],
      "metadata": {
        "id": "0QBsHVMsy6Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_confusion_matrix, ax = plt.subplots(1,1,figsize=(7,4))\n",
        "ConfusionMatrixDisplay(confusion_matrix(predictions.argmax(axis=1),\n",
        "                                        test_y.argmax(axis=1)),\n",
        "                       display_labels=lb.classes_).plot(values_format=\".0f\",ax=ax)\n",
        "\n",
        "ax.set_xlabel(\"True Label\")\n",
        "ax.set_ylabel(\"Predicted Label\")\n",
        "ax.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZtlW8dcMy6Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading figures\n",
        "logger.info(\"Uploading figures\")\n",
        "run.log(\n",
        "    {\n",
        "        \"confusion_matrix\": wandb.Image(fig_confusion_matrix),\n",
        "        # \"other_figure\": wandb.Image(other_fig)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "l6FKVFAly6Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "logger.info(\"Validation Evaluation metrics\")\n",
        "fbeta = fbeta_score(test_y.argmax(axis=1), \n",
        "                    predictions.argmax(axis=1), \n",
        "                    beta=1, zero_division=1,average='weighted')\n",
        "precision = precision_score(test_y.argmax(axis=1),\n",
        "                            predictions.argmax(axis=1),\n",
        "                            zero_division=1,average='weighted')\n",
        "recall = recall_score(test_y.argmax(axis=1),\n",
        "                      predictions.argmax(axis=1),\n",
        "                      zero_division=1,average='weighted')\n",
        "acc = accuracy_score(test_y.argmax(axis=1),\n",
        "                     predictions.argmax(axis=1))\n",
        "\n",
        "logger.info(\"Validation Accuracy: {}\".format(acc))\n",
        "logger.info(\"Validation Precision: {}\".format(precision))\n",
        "logger.info(\"Validation Recall: {}\".format(recall))\n",
        "logger.info(\"Validation F1: {}\".format(fbeta))\n",
        "\n",
        "run.summary[\"Acc\"] = acc\n",
        "run.summary[\"Precision\"] = precision\n",
        "run.summary[\"Recall\"] = recall\n",
        "run.summary[\"F1\"] = fbeta\n",
        "# number of parameters\n",
        "run.summary[\"Count_Params\"] = model.count_params()\n",
        "# energy unit is kWh\n",
        "run.summary[\"Energy_Consumed\"] = tracker.final_emissions_data.energy_consumed\n",
        "run.summary[\"Energy_RAM\"] = tracker.final_emissions_data.ram_energy\n",
        "run.summary[\"Energy_GPU\"] = tracker.final_emissions_data.gpu_energy\n",
        "run.summary[\"Energy_CPU\"] = tracker.final_emissions_data.cpu_energy\n",
        "# kg\n",
        "run.summary[\"CO2_Emissions\"] = tracker.final_emissions_data.emissions"
      ],
      "metadata": {
        "id": "vcADzUqyy6Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "0zXbec0uy6Gs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}