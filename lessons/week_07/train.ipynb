{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ApYpc47MFOYi"],"toc_visible":true,"authorship_tag":"ABX9TyMY+PLXt+FR3UVy74FtNGmU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"j4RpK9pawQzP"},"source":["# Your First Image Classifier: Using CNN to Classify Images\n","# Train"]},{"cell_type":"markdown","metadata":{"id":"vbuzxq-b90j-"},"source":["The purpose of this dataset is to correctly classify an image as containing a dog, cat, or panda.\n","Containing only 3,000 images, the Animals dataset is meant to be another **introductory** dataset\n","that we can quickly train a CNN model and obtain a comparative results with the previous KNN model.\n","\n","\n","Let's take the following steps:\n","\n","1. Encoding target variable\n","2. Training the CNN model\n","3. Export the model and the encoder object\n","\n","<center><img width=\"900\" src=\"https://drive.google.com/uc?export=view&id=1haMB_Zt6Et9q9sPHxfuR4g3FT5QRXlTI\"></center>\n"]},{"cell_type":"markdown","metadata":{"id":"ApYpc47MFOYi"},"source":["## Step 01: Setup"]},{"cell_type":"markdown","metadata":{"id":"ULBka-lQFJW9"},"source":["Start out by installing the experiment tracking library and setting up your free W&B account:\n","\n","\n","*   **pip install wandb** – Install the W&B library\n","*   **import wandb** – Import the wandb library\n","*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWnFIWPuFXej"},"outputs":[],"source":["!pip install wandb -qU"]},{"cell_type":"code","source":["# a Python package for tracking the carbon emissions produced by various\n","# kinds of computer programs, from straightforward algorithms to deep neural networks.\n","!pip install codecarbon"],"metadata":{"id":"NBqatao0jyp5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcrOk6pURp50"},"source":["### Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJaCNlDDRz6d"},"outputs":[],"source":["import logging\n","import joblib\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.optimizers import SGD\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from codecarbon import EmissionsTracker\n","from tensorflow.keras.callbacks import Callback\n","from wandb.keras import WandbCallback\n","import os\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import wandb"]},{"cell_type":"code","source":["wandb.login()"],"metadata":{"id":"7ee2tdx7Cnfs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configure logging\n","# reference for a logging obj\n","logger = logging.getLogger()\n","\n","# set level of logging\n","logger.setLevel(logging.INFO)\n","\n","# create handlers\n","c_handler = logging.StreamHandler()\n","c_format = logging.Formatter(fmt=\"%(asctime)s %(message)s\",datefmt='%d-%m-%Y %H:%M:%S')\n","c_handler.setFormatter(c_format)\n","\n","# add handler to the logger\n","logger.handlers[0] = c_handler"],"metadata":{"id":"Xq0zG_132yC2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m-XgvGlGx-n_"},"source":["## Step 02 Basic configuration and download artifacts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlLArYonw4pJ"},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","  \"project_name\": \"cnn_classifier\",\n","  \"train_feature_artifact\": \"train_x:latest\",\n","  \"train_target_artifact\": \"train_y:latest\",\n","  \"val_feature_artifact\": \"val_x:latest\",\n","  \"val_target_artifact\": \"val_y:latest\",\n","  \"encoder\": \"target_encoder\",\n","  \"inference_model\": \"model.h5\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3kCOus2wzbw"},"outputs":[],"source":["# open the W&B project created in the Fetch step\n","run = wandb.init(entity=\"ivanovitch-silva\",project=args[\"project_name\"], job_type=\"Train\")\n","\n","logger.info(\"Downloading the train and validation data\")\n","# train x\n","train_x_artifact = run.use_artifact(args[\"train_feature_artifact\"])\n","train_x_path = train_x_artifact.file()\n","\n","# train y\n","train_y_artifact = run.use_artifact(args[\"train_target_artifact\"])\n","train_y_path = train_y_artifact.file()\n","\n","# validation x\n","val_x_artifact = run.use_artifact(args[\"val_feature_artifact\"])\n","val_x_path = val_x_artifact.file()\n","\n","# validation y\n","val_y_artifact = run.use_artifact(args[\"val_target_artifact\"])\n","val_y_path = val_y_artifact.file()\n","\n","# unpacking the artifacts\n","train_x = joblib.load(train_x_path)\n","train_y = joblib.load(train_y_path)\n","val_x = joblib.load(val_x_path)\n","val_y = joblib.load(val_y_path)"]},{"cell_type":"code","source":["logger.info(\"Train x: {}\".format(train_x.shape))\n","logger.info(\"Train y: {}\".format(train_y.shape))\n","logger.info(\"Validation x: {}\".format(val_x.shape))\n","logger.info(\"Validation y: {}\".format(val_y.shape))"],"metadata":{"id":"81mqk7Z2DMOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 03: Encoder the target variable"],"metadata":{"id":"68hjvjv-JzEz"}},{"cell_type":"code","source":["# encode the labels as Binarizers\n","lb = LabelBinarizer()\n","\n","# take care not to produce data lakeage\n","train_y = lb.fit_transform(train_y)\n","val_y = lb.transform(val_y)"],"metadata":{"id":"Ht06smfRwngl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lb.classes_"],"metadata":{"id":"BVYLnb1bKUu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y[4]"],"metadata":{"id":"DuTIUfm2KRuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_y[3]"],"metadata":{"id":"Ln7wJ93FKZex"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 04: Model definition"],"metadata":{"id":"ggiDYSthKfMZ"}},{"cell_type":"markdown","source":["Source code based on **Rosebrock, Adrian. Deep Learning For Computer vision with Python, 2019** [link](https://pyimagesearch.com/deep-learning-computer-vision-python-book/)"],"metadata":{"id":"b0pYGw2LK0Vy"}},{"cell_type":"code","source":["class ShallowNet:\n","\t@staticmethod\n","\tdef build(width, height, depth, classes):\n","\t\t# initialize the model along with the input shape to be\n","\t\t# \"channels last\"\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\n","\t\t# define the first (and only) CONV => RELU layer\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\n","\n","\t\t# softmax classifier\n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(classes))\n","\t\tmodel.add(Activation(\"softmax\"))\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"],"metadata":{"id":"BBkEAue-KwQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a model object\n","model = ShallowNet.build(32,32,3,3)\n","\n","# summarize layers\n","model.summary()"],"metadata":{"id":"aht6tkQILWaf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 05: Training"],"metadata":{"id":"T9hAAmxudSAU"}},{"cell_type":"code","source":["# create codecarbon tracker\n","# codecarbon is too much verbose, change the log level for more info\n","tracker = EmissionsTracker(log_level=\"critical\")\n","tracker.start()\n","\n","# initialize the optimizer and model\n","print(\"[INFO] compiling model...\")\n","opt = SGD(learning_rate=0.005)\n","model = ShallowNet.build(width=32, height=32, depth=3, classes=3)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n","\n","# train the network\n","print(\"[INFO] training network...\")\n","history = model.fit(train_x, train_y, \n","              validation_data=(val_x, val_y),\n","              batch_size=32, \n","              epochs=100, \n","              verbose=0,\n","              callbacks=[wandb.keras.WandbCallback(save_model=False,\n","                                                   compute_flops=True)]\n","          )\n","\n","# get co2 emissions from tracker\n","# \"CO2 emission (in Kg)\"\n","emissions = tracker.stop()"],"metadata":{"id":"9j_awuNTdh1l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 06: Evaluation Metrics"],"metadata":{"id":"JOgzx5LhEPhB"}},{"cell_type":"code","source":["# plot the training loss and accuracy\n","plt.style.use(\"ggplot\")\n","fig, ax = plt.subplots(1,1,figsize=(10,8))\n","\n","ax.plot(np.arange(0, 100), history.history[\"loss\"], label=\"train_loss\",linestyle='--')\n","ax.plot(np.arange(0, 100), history.history[\"val_loss\"], label=\"val_loss\",linestyle='--')\n","ax.plot(np.arange(0, 100), history.history[\"accuracy\"], label=\"train_acc\")\n","ax.plot(np.arange(0, 100), history.history[\"val_accuracy\"], label=\"val_acc\")\n","ax.set_title(\"Training Loss and Accuracy\")\n","ax.set_xlabel(\"Epoch #\")\n","ax.set_ylabel(\"Loss/Accuracy\")\n","ax.legend()\n","plt.show()"],"metadata":{"id":"XxdbI3o4kXqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"[INFO] {} kWh of electricity used since the begining\".format(tracker.final_emissions_data.energy_consumed))\n","print(\"[INFO] Energy consumed for RAM: {} kWh\".format(tracker.final_emissions_data.ram_energy))\n","print(\"[INFO] Energy consumed for all GPU: {} kWh\".format(tracker.final_emissions_data.gpu_energy))\n","print(\"[INFO] Energy consumed for all CPU: {} kWh\".format(tracker.final_emissions_data.cpu_energy))\n","print(\"[INFO] CO2 emission {}(in Kg)\".format(tracker.final_emissions_data.emissions))"],"metadata":{"id":"pb_roodzuH2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate the network\n","print(\"[INFO] evaluating network...\")\n","predictions = model.predict(val_x, batch_size=32)\n","print(classification_report(val_y.argmax(axis=1),\n","                            predictions.argmax(axis=1),\n","                            target_names=lb.classes_))"],"metadata":{"id":"9e5ozfDaAo6I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig_confusion_matrix, ax = plt.subplots(1,1,figsize=(7,4))\n","ConfusionMatrixDisplay(confusion_matrix(predictions.argmax(axis=1),\n","                                        val_y.argmax(axis=1)),\n","                       display_labels=lb.classes_).plot(values_format=\".0f\",ax=ax)\n","\n","ax.set_xlabel(\"True Label\")\n","ax.set_ylabel(\"Predicted Label\")\n","ax.grid(False)\n","plt.show()"],"metadata":{"id":"-63tXNhAFwQN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Uploading figures\n","logger.info(\"Uploading figures\")\n","run.log(\n","    {\n","        \"confusion_matrix\": wandb.Image(fig_confusion_matrix),\n","        # \"other_figure\": wandb.Image(other_fig)\n","    }\n",")"],"metadata":{"id":"bi7ugT4pHA_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluation Metrics\n","logger.info(\"Validation Evaluation metrics\")\n","fbeta = fbeta_score(val_y.argmax(axis=1), \n","                    predictions.argmax(axis=1), \n","                    beta=1, zero_division=1,average='weighted')\n","precision = precision_score(val_y.argmax(axis=1),\n","                            predictions.argmax(axis=1),\n","                            zero_division=1,average='weighted')\n","recall = recall_score(val_y.argmax(axis=1),\n","                      predictions.argmax(axis=1),\n","                      zero_division=1,average='weighted')\n","acc = accuracy_score(val_y.argmax(axis=1),\n","                     predictions.argmax(axis=1))\n","\n","logger.info(\"Validation Accuracy: {}\".format(acc))\n","logger.info(\"Validation Precision: {}\".format(precision))\n","logger.info(\"Validation Recall: {}\".format(recall))\n","logger.info(\"Validation F1: {}\".format(fbeta))\n","\n","run.summary[\"Acc\"] = acc\n","run.summary[\"Precision\"] = precision\n","run.summary[\"Recall\"] = recall\n","run.summary[\"F1\"] = fbeta\n","# number of parameters\n","run.summary[\"Count_Params\"] = model.count_params()\n","# energy unit is kWh\n","run.summary[\"Energy_Consumed\"] = tracker.final_emissions_data.energy_consumed\n","run.summary[\"Energy_RAM\"] = tracker.final_emissions_data.ram_energy\n","run.summary[\"Energy_GPU\"] = tracker.final_emissions_data.gpu_energy\n","run.summary[\"Energy_CPU\"] = tracker.final_emissions_data.cpu_energy\n","# kg\n","run.summary[\"CO2_Emissions\"] = tracker.final_emissions_data.emissions"],"metadata":{"id":"9iOE5gXOB-tI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger.info(\"Dumping the model and encoder artifacts to the disk\")\n","\n","# Save the artifacts using joblib\n","joblib.dump(lb, args[\"encoder\"])\n","model.save(os.path.join(wandb.run.dir, args[\"inference_model\"]))"],"metadata":{"id":"rnWPb4pTxW0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encoder artifact\n","artifact = wandb.Artifact(args[\"encoder\"],\n","                          type=\"INFERENCE_MODEL\",\n","                          description=\"A json file representing the target encoder\"\n","                          )\n","\n","logger.info(\"Logging the target encoder artifact\")\n","artifact.add_file(args[\"encoder\"])\n","run.log_artifact(artifact)"],"metadata":{"id":"dI3qHb2yy98B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inference model artifact\n","artifact = wandb.Artifact(args[\"inference_model\"],\n","                          type=\"INFERENCE_MODEL\",\n","                          description=\"A json file representing the inference model\"\n","                          )\n","\n","logger.info(\"Logging the inference model artifact\")\n","artifact.add_file(os.path.join(wandb.run.dir, args[\"inference_model\"]))\n","run.log_artifact(artifact)"],"metadata":{"id":"VvgTyWkt05sK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run.finish()"],"metadata":{"id":"wpA5T4NR1Fpk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 07: How can we improve this model?"],"metadata":{"id":"pE_6EmjCrDlr"}},{"cell_type":"markdown","source":["-  Data Augmentation [Link](https://colab.research.google.com/drive/1S8SJvH4bqhPvurG4gjh3-t-XulX4S8JX#scrollTo=me4Jr5IhaT0j)\n","- Batch Normalization\n","- Dropout\n","- Add more CNN layers\n","- Add more hidden layers in the head"],"metadata":{"id":"BLUjdXqVLdvO"}}]}