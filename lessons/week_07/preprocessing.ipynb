{"cells":[{"cell_type":"markdown","metadata":{"id":"j4RpK9pawQzP"},"source":["# Your First Image Classifier: Using CNN to Classify Images\n","# Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"vbuzxq-b90j-"},"source":["The purpose of this dataset is to correctly classify an image as containing a dog, cat, or panda.\n","Containing only 3,000 images, the Animals dataset is meant to be another **introductory** dataset\n","that we can quickly train a CNN model and obtain a comparative results with the previous KNN model.\n","\n","Let's take the following steps:\n","\n","1. Fetch Data (reuse of the previous project)\n","2. Pre-processing\n","3. Clean data\n","\n","<center><img width=\"900\" src=\"https://drive.google.com/uc?export=view&id=1haMB_Zt6Et9q9sPHxfuR4g3FT5QRXlTI\"></center>\n"]},{"cell_type":"markdown","metadata":{"id":"ApYpc47MFOYi"},"source":["## Step 01: Setup"]},{"cell_type":"markdown","metadata":{"id":"ULBka-lQFJW9"},"source":["Start out by installing the experiment tracking library and setting up your free W&B account:\n","\n","\n","*   **pip install wandb** – Install the W&B library\n","*   **import wandb** – Import the wandb library\n","*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWnFIWPuFXej"},"outputs":[],"source":["!pip install wandb -qU"]},{"cell_type":"markdown","metadata":{"id":"wcrOk6pURp50"},"source":["### Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJaCNlDDRz6d"},"outputs":[],"source":["# import the necessary packages\n","from imutils import paths\n","import logging\n","import os\n","import cv2\n","import numpy as np\n","import joblib\n","import tensorflow as tf\n","import wandb"]},{"cell_type":"code","source":["wandb.login()"],"metadata":{"id":"GaqfBz4Ol3p8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkIkAWcL-4x7"},"outputs":[],"source":["# configure logging\n","# reference for a logging obj\n","logger = logging.getLogger()\n","\n","# set level of logging\n","logger.setLevel(logging.INFO)\n","\n","# create handlers\n","c_handler = logging.StreamHandler()\n","c_format = logging.Formatter(fmt=\"%(asctime)s %(message)s\",datefmt='%d-%m-%Y %H:%M:%S')\n","c_handler.setFormatter(c_format)\n","\n","# add handler to the logger\n","logger.handlers[0] = c_handler"]},{"cell_type":"markdown","metadata":{"id":"m-XgvGlGx-n_"},"source":["## Step 02: Fetch Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlLArYonw4pJ"},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","\t\"dataset\": \"animals\",\n","  \"project_name\": \"first_image_classifier\",\n","  \"artifact_name\": \"animals_raw_data:latest\",\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3kCOus2wzbw"},"outputs":[],"source":["# open the W&B project created in the Fetch step\n","run = wandb.init(entity=\"ivanovitch-silva\",project=args[\"project_name\"], job_type=\"preprocessing\")\n","\n","# download the raw data from W&B\n","raw_data = run.use_artifact(args[\"artifact_name\"])\n","data_dir = raw_data.download()\n","logger.info(\"Path: {}\".format(data_dir))"]},{"cell_type":"code","source":["run.finish()"],"metadata":{"id":"r-aLVJrYFtSV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z4hRGKj23tJQ"},"source":["## Step 03 - Clean Data"]},{"cell_type":"markdown","source":["### Project Config."],"metadata":{"id":"9RpRG_c2JNjd"}},{"cell_type":"code","source":["data_dir"],"metadata":{"id":"GcZcyjj0GCC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rlVvuII53sR"},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","\t\"features\": \"clean_features\",\n","  \"target\": \"labels\",\n","  \"project_name\": \"cnn_classifier\"\n","}"]},{"cell_type":"code","source":["# open the W&B project created in the Fetch step\n","run = wandb.init(entity=\"ivanovitch-silva\",project=args[\"project_name\"], job_type=\"preprocessing\")"],"metadata":{"id":"YvF_qIB5NlKm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loader and Preprocessing Classes"],"metadata":{"id":"O_5dUXUKJVyQ"}},{"cell_type":"markdown","source":["Source code based on **Rosebrock, Adrian. Deep Learning For Computer vision with Python, 2019** [link](https://pyimagesearch.com/deep-learning-computer-vision-python-book/)"],"metadata":{"id":"gciJIGOgDHOg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEeK-4xH69L7"},"outputs":[],"source":["# \n","# a basic simple preprocessor that resize a image\n","#\n","class SimplePreprocessor:\n","\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n","\t\t# store the target image width, height, and interpolation\n","\t\t# method used when resizing\n","\t\tself.width = width\n","\t\tself.height = height\n","\t\tself.inter = inter\n","\n","\tdef preprocess(self, image):\n","\t\t# resize the image to a fixed size, ignoring the aspect\n","\t\t# ratio\n","\t\treturn cv2.resize(image, (self.width, self.height),interpolation=self.inter)"]},{"cell_type":"code","source":["#\n","# Rearrange the dimension of an image and return a numpy array\n","# Default dimension is (heigh, width, channel)\n","#\n","class ImageToArrayPreprocessor:\n","\tdef __init__(self, dataFormat=None):\n","\t\t# store the image data format\n","\t\tself.dataFormat = dataFormat\n","\n","\tdef preprocess(self, image):\n","\t\t# apply the Keras utility function that correctly rearranges\n","\t\t# the dimensions of the image\n","\t\treturn tf.keras.utils.img_to_array(image, data_format=self.dataFormat)"],"metadata":{"id":"t7lYi1pAIica"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_YLPvoP7OjX"},"outputs":[],"source":["# Building an image loader\n","class SimpleDatasetLoader:\n","  def __init__(self, preprocessors=None, logger=None):\n","\t\t# store the image preprocessor\n","    self.preprocessors = preprocessors\n","    self.logger = logger\n","\n","\t\t# if the preprocessors are None, initialize them as an\n","\t\t# empty list\n","    if self.preprocessors is None:\n","      self.preprocessors = []\n","\n","  def load(self, imagePaths, verbose=-1):\n","\t\t# initialize the list of features and labels\n","    data = []\n","    labels = []\n","\n","\t\t# loop over the input images\n","    for (i, imagePath) in enumerate(imagePaths):\n","\t\t\t# load the image and extract the class label assuming\n","\t\t\t# that our path has the following format:\n","\t\t\t# /path/to/dataset/{class}/{image}.jpg\n","\t\t\t# e.g \"img example: ./artifacts/animals_raw_data:v0/dogs/dogs_00892.jpg\"\n","\t\t\t# imagePath.split(os.path.sep)[-2] will return \"dogs\"\n","      image = cv2.imread(imagePath)\n","      label = imagePath.split(os.path.sep)[-2]\n","\n","      # check to see if our preprocessors are not None\n","      if self.preprocessors is not None:\n","\t\t\t\t# loop over the preprocessors and apply each to\n","\t\t\t\t# the image\n","        for p in self.preprocessors:\n","          image = p.preprocess(image)\n","\n","\t\t\t# treat our processed image as a \"feature vector\"\n","\t\t\t# by updating the data list followed by the labels\n","      data.append(image)\n","      labels.append(label)\n","   \n","\t\t\t# show an update every `verbose` images\n","      if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n","        logger.info(\"[INFO] processed {}/{}\".format(i + 1,len(imagePaths)))\n","\n","\t\t# return a tuple of the data and labels\n","    return (np.array(data), np.array(labels))"]},{"cell_type":"markdown","source":["### Cleaning"],"metadata":{"id":"2KmT8j1SMfNq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OC8kcWO07wxB"},"outputs":[],"source":["# grab the list of images that we'll be describing\n","logger.info(\"[INFO] preprocessing images...\")\n","imagePaths = list(paths.list_images(data_dir))\n","\n","# initialize the image preprocessors\n","sp = SimplePreprocessor(32, 32)\n","iap = ImageToArrayPreprocessor()\n","\n","# load the dataset from disk then scale the raw pixel intensities\n","# to the range [0, 1]\n","sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n","(data, labels) = sdl.load(imagePaths, verbose=500)\n","data = data.astype(\"float\") / 255.0\n","\n","# show some information on memory consumption of the images\n","logger.info(\"[INFO] features matrix: {:.1f}MB\".format(data.nbytes / (1024 * 1024)))\n","logger.info(\"[INFO] labels vector: {:.1f}MB\".format(labels.nbytes / (1024 * 1024)))\n","logger.info(\"[INFO] features shape: {}, labels shape: {}\".format(data.shape,labels.shape))"]},{"cell_type":"markdown","source":["### Dump the artifacts to disk and upload to W&B"],"metadata":{"id":"yPexHIfcNHm_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9KK4Jii8pJe"},"outputs":[],"source":["# Save the feature artifacts using joblib\n","joblib.dump(data, args[\"features\"])\n","\n","# Save the target using joblib\n","joblib.dump(labels, args[\"target\"])\n","\n","logger.info(\"Dumping the clean data artifacts to disk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bnnmdpK9BLD2"},"outputs":[],"source":["# clean data artifact\n","artifact = wandb.Artifact(args[\"features\"],\n","                          type=\"CLEAN_DATA\",\n","                          description=\"A json file representing the clean features data\"\n","                          )\n","\n","logger.info(\"Logging clean data artifact\")\n","artifact.add_file(args[\"features\"])\n","run.log_artifact(artifact)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RxuZTgACWVw"},"outputs":[],"source":["# clean label artifact\n","artifact = wandb.Artifact(args[\"target\"],\n","                          type=\"CLEAN_DATA\",\n","                          description=\"A json file representing the clean target\"\n","                          )\n","\n","logger.info(\"Logging clean target artifact\")\n","artifact.add_file(args[\"target\"])\n","run.log_artifact(artifact)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49Ivx0SQCkhT"},"outputs":[],"source":["run.finish()"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyNtki8+bos3goxnJjJo3KR0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}