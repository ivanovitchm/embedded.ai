{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP919AMOyya+W68F9RTbV5r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"j4RpK9pawQzP"},"source":["# Your First Image Classifier: Using k-NN to Classify Images\n","# Test"]},{"cell_type":"markdown","metadata":{"id":"vbuzxq-b90j-"},"source":["The purpose of this dataset is to correctly classify an image as containing a dog, cat, or panda.\n","Containing only 3,000 images, the Animals dataset is meant to be another **introductory** dataset\n","that we can quickly train a KNN model and obtain initial results (no so good accuracy) that has potential to be used as a baseline. \n","\n","Let's take the following steps:\n","\n","1. Download the encoder and model artifacts\n","2. Evaluate the model using the test dataset\n","3. Create an interactive table\n","\n","<center><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1a-nyAPNPiVh-Xb2Pu2t2p-BhSvHJS0pO\"></center>"]},{"cell_type":"markdown","metadata":{"id":"ApYpc47MFOYi"},"source":["## Step 01: Setup"]},{"cell_type":"markdown","metadata":{"id":"ULBka-lQFJW9"},"source":["Start out by installing the experiment tracking library and setting up your free W&B account:\n","\n","\n","*   **pip install wandb** – Install the W&B library\n","*   **import wandb** – Import the wandb library\n","*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWnFIWPuFXej"},"outputs":[],"source":["!pip install wandb -qU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zehpII7IFk2z"},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"wcrOk6pURp50"},"source":["### Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJaCNlDDRz6d"},"outputs":[],"source":["# import the necessary packages\n","from imutils import paths\n","import logging\n","import os\n","import cv2\n","import numpy as np\n","import joblib\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import re"]},{"cell_type":"code","source":["# configure logging\n","# reference for a logging obj\n","logger = logging.getLogger()\n","\n","# set level of logging\n","logger.setLevel(logging.INFO)\n","\n","# create handlers\n","c_handler = logging.StreamHandler()\n","c_format = logging.Formatter(fmt=\"%(asctime)s %(message)s\",datefmt='%d-%m-%Y %H:%M:%S')\n","c_handler.setFormatter(c_format)\n","\n","# add handler to the logger\n","logger.handlers[0] = c_handler"],"metadata":{"id":"Xq0zG_132yC2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m-XgvGlGx-n_"},"source":["## Step 02 Test evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlLArYonw4pJ"},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","  \"project_name\": \"first_image_classifier\",\n","  \"test_feature_artifact\": \"test_x:latest\",\n","  \"test_target_artifact\": \"test_y:latest\",\n","  \"encoder\": \"target_encoder:latest\",\n","  \"inference_model\": \"model:latest\",\n","  \"deploy\": \"inference_result\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3kCOus2wzbw"},"outputs":[],"source":["# open the W&B project created in the Fetch step\n","run = wandb.init(entity=\"ivanovitch-silva\",project=args[\"project_name\"], job_type=\"Test\")\n","\n","logger.info(\"Downloading the test data\")\n","test_x_artifact = run.use_artifact(args[\"test_feature_artifact\"])\n","test_x_path = test_x_artifact.file()\n","test_y_artifact = run.use_artifact(args[\"test_target_artifact\"])\n","test_y_path = test_y_artifact.file()\n","\n","# unpacking the artifacts\n","test_x = joblib.load(test_x_path)\n","test_y = joblib.load(test_y_path)"]},{"cell_type":"code","source":["logger.info(\"Downloading the encoder and inference model\")\n","encoder_artifact = run.use_artifact(args[\"encoder\"])\n","encoder_path = encoder_artifact.file()\n","model_artifact = run.use_artifact(args[\"inference_model\"])\n","model_path = model_artifact.file()\n","\n","# unpacking the artifacts\n","encoder = joblib.load(encoder_path)\n","model = joblib.load(model_path)"],"metadata":{"id":"ihQjf0rZFufG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encode the labels as integers\n","test_y = encoder.transform(test_y)\n","\n","# train a k-NN classifier on the raw pixel intensities\n","logger.info(\"[INFO] evaluating k-NN classifier...\")\n","predict = model.predict(test_x)"],"metadata":{"id":"Ht06smfRwngl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(test_y, predict,target_names=encoder.classes_))"],"metadata":{"id":"ZQWbngJ8HH6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluation Metrics\n","logger.info(\"Test Evaluation metrics\")\n","fbeta = fbeta_score(test_y, predict, beta=1, zero_division=1,average='weighted')\n","precision = precision_score(test_y, predict, zero_division=1,average='weighted')\n","recall = recall_score(test_y, predict, zero_division=1,average='weighted')\n","acc = accuracy_score(test_y, predict)\n","\n","logger.info(\"Test Accuracy: {}\".format(acc))\n","logger.info(\"Test Precision: {}\".format(precision))\n","logger.info(\"Test Recall: {}\".format(recall))\n","logger.info(\"Test F1: {}\".format(fbeta))\n","\n","run.summary[\"Acc\"] = acc\n","run.summary[\"Precision\"] = precision\n","run.summary[\"Recall\"] = recall\n","run.summary[\"F1\"] = fbeta"],"metadata":{"id":"GoN29mwaIeGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder.classes_"],"metadata":{"id":"IjWxNBylKLf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig_confusion_matrix, ax = plt.subplots(1,1,figsize=(7,4))\n","ConfusionMatrixDisplay(confusion_matrix(predict,test_y),\n","                       display_labels=encoder.classes_).plot(values_format=\".0f\",ax=ax)\n","\n","ax.set_xlabel(\"True Label\")\n","ax.set_ylabel(\"Predicted Label\")\n","plt.show()"],"metadata":{"id":"ugYaUZLPIxcd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Uploading figures\n","logger.info(\"Uploading figures\")\n","run.log(\n","    {\n","        \"confusion_matrix\": wandb.Image(fig_confusion_matrix),\n","        # \"other_figure\": wandb.Image(other_fig)\n","    }\n",")"],"metadata":{"id":"IE_o1J11KCLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a folder named 'test'\n","dirname = 'test'\n","os.mkdir(dirname)\n","\n","# re-generate test images and put all of them in test/ folder\n","for i in range(test_x.shape[0]):\n","  img = test_x[i].reshape(32,32,3)\n","  cv2.imwrite(os.path.join(dirname,''.join([str(i),'.jpg'])),img)"],"metadata":{"id":"NJdc8B4dSJGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sort image Paths by name\n","# 0.jpg, 1.jpg, 2.jpg, ....\n","imagePaths = list(paths.list_images(\"test\"))\n","imagePaths = sorted(imagePaths, key=lambda x: int(re.search(r\"(\\d+)\\.[a-z]+$\", x).group(1)))"],"metadata":{"id":"3GKkTiU1F0Ix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a table with columns we want to track/compare\n","preview_dt = wandb.Table(columns=[\"test id\",\"image\", \"target\",\"predict\"])\n","\n","# create a new artifact to store the EDA data\n","inference_result = wandb.Artifact(args[\"deploy\"], type=\"INFERENCE\")"],"metadata":{"id":"wFBs_dIgHyMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# append all images to the artifact\n","for i,img in enumerate(imagePaths):\n","  image = cv2.imread(img)\n","  preview_dt.add_data(i, \n","                      wandb.Image(img), \n","                      encoder.inverse_transform([test_y[i]])[0], \n","                      encoder.inverse_transform([predict[i]])[0])"],"metadata":{"id":"SL8KuR1AJD6K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save artifact to W&B\n","inference_result.add(preview_dt, \"Inference_Table\")\n","run.log_artifact(inference_result)"],"metadata":{"id":"6eQ0O6E0JHnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run.finish()"],"metadata":{"id":"AIT_98xXJL3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"e3pTuzmTKNEt"},"execution_count":null,"outputs":[]}]}