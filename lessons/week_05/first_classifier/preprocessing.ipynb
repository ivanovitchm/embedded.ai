{"cells":[{"cell_type":"markdown","metadata":{"id":"j4RpK9pawQzP"},"source":["# Your First Image Classifier: Using k-NN to Classify Images\n","# Exploratory Data Analysis and Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"vbuzxq-b90j-"},"source":["The purpose of this dataset is to correctly classify an image as containing a dog, cat, or panda.\n","Containing only 3,000 images, the Animals dataset is meant to be another **introductory** dataset\n","that we can quickly train a KNN model and obtain initial results (no so good accuracy) that has potential to be used as a baseline. \n","\n","Let's take the following steps:\n","\n","1. Exploratory Data Analysis (EDA)\n","2. Pre-processing\n","\n","<center><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1a-nyAPNPiVh-Xb2Pu2t2p-BhSvHJS0pO\"></center>"]},{"cell_type":"markdown","metadata":{"id":"ApYpc47MFOYi"},"source":["## Step 01: Setup"]},{"cell_type":"markdown","metadata":{"id":"ULBka-lQFJW9"},"source":["Start out by installing the experiment tracking library and setting up your free W&B account:\n","\n","\n","*   **pip install wandb** – Install the W&B library\n","*   **import wandb** – Import the wandb library\n","*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWnFIWPuFXej"},"outputs":[],"source":["!pip install wandb -qU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zehpII7IFk2z"},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"wcrOk6pURp50"},"source":["### Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJaCNlDDRz6d"},"outputs":[],"source":["# import the necessary packages\n","from imutils import paths\n","import logging\n","import os\n","import cv2\n","import numpy as np\n","import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkIkAWcL-4x7"},"outputs":[],"source":["# configure logging\n","# reference for a logging obj\n","logger = logging.getLogger()\n","\n","# set level of logging\n","logger.setLevel(logging.INFO)\n","\n","# create handlers\n","c_handler = logging.StreamHandler()\n","c_format = logging.Formatter(fmt=\"%(asctime)s %(message)s\",datefmt='%d-%m-%Y %H:%M:%S')\n","c_handler.setFormatter(c_format)\n","\n","# add handler to the logger\n","logger.handlers[0] = c_handler"]},{"cell_type":"markdown","metadata":{"id":"m-XgvGlGx-n_"},"source":["## Step 02 EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlLArYonw4pJ"},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","\t\"dataset\": \"animals\",\n","  \"project_name\": \"first_image_classifier\",\n","  \"artifact_name\": \"animals_raw_data:latest\",\n","  \"eda_name\": \"eda_animals\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3kCOus2wzbw"},"outputs":[],"source":["# open the W&B project created in the Fetch step\n","run = wandb.init(entity=\"ivanovitch-silva\",project=args[\"project_name\"], job_type=\"preprocessing\")\n","\n","# download the raw data from W&B\n","raw_data = run.use_artifact(args[\"artifact_name\"])\n","data_dir = raw_data.download()\n","logger.info(\"Path: {}\".format(data_dir))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxDFSuYpyJCe"},"outputs":[],"source":["# create a table with columns we want to track/compare\n","preview_dt = wandb.Table(columns=[\"id\", \"image\", \"label\",\"size\"])\n","\n","# create a new artifact to store the EDA data\n","eda_data = wandb.Artifact(args[\"eda_name\"], type=\"eda_data\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmtbBJrbzPTG"},"outputs":[],"source":["# grab the list of images that we'll be describing\n","imagePaths = list(paths.list_images(data_dir))\n","\n","# append all images to the artifact\n","for img in imagePaths:\n","  \"img example: ./artifacts/animals_raw_data:v0/dogs/dogs_00892.jpg\"\n","  label = img.split(os.path.sep)\n","  image = cv2.imread(img)\n","  preview_dt.add_data(label[-1], wandb.Image(img), label[-2], str(image.shape[0]) + \" X \" + str(image.shape[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ue_rx5V5GPt"},"outputs":[],"source":["# save artifact to W&B\n","eda_data.add(preview_dt, \"EDA_Table\")\n","run.log_artifact(eda_data)"]},{"cell_type":"markdown","metadata":{"id":"z4hRGKj23tJQ"},"source":["## Step 03 - Clean Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rlVvuII53sR"},"outputs":[],"source":["# since we are using Jupyter Notebooks we can replace our argument\n","# parsing code with *hard coded* arguments and values\n","args = {\n","\t\"dataset\": \"clean_data\",\n","  \"label\": \"label\",\n","  \"project_name\": \"first_image_classifier\",\n","  \"artifact_name\": \"animals_raw_data:latest\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1946YcY6goU"},"outputs":[],"source":["# download the raw data from W&B\n","raw_data = run.use_artifact(args[\"artifact_name\"])\n","data_dir = raw_data.download()\n","logger.info(\"Path: {}\".format(data_dir))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEeK-4xH69L7"},"outputs":[],"source":["# a basic simple preprocessor\n","class SimplePreprocessor:\n","\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n","\t\t# store the target image width, height, and interpolation\n","\t\t# method used when resizing\n","\t\tself.width = width\n","\t\tself.height = height\n","\t\tself.inter = inter\n","\n","\tdef preprocess(self, image):\n","\t\t# resize the image to a fixed size, ignoring the aspect\n","\t\t# ratio\n","\t\treturn cv2.resize(image, (self.width, self.height),interpolation=self.inter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_YLPvoP7OjX"},"outputs":[],"source":["# Building an image loader\n","class SimpleDatasetLoader:\n","  def __init__(self, preprocessors=None, logger=None):\n","\t\t# store the image preprocessor\n","    self.preprocessors = preprocessors\n","    self.logger = logger\n","\n","\t\t# if the preprocessors are None, initialize them as an\n","\t\t# empty list\n","    if self.preprocessors is None:\n","      self.preprocessors = []\n","\n","  def load(self, imagePaths, verbose=-1):\n","\t\t# initialize the list of features and labels\n","    data = []\n","    labels = []\n","\n","\t\t# loop over the input images\n","    for (i, imagePath) in enumerate(imagePaths):\n","\t\t\t# load the image and extract the class label assuming\n","\t\t\t# that our path has the following format:\n","\t\t\t# /path/to/dataset/{class}/{image}.jpg\n","\t\t\t# e.g \"img example: ./artifacts/animals_raw_data:v0/dogs/dogs_00892.jpg\"\n","\t\t\t# imagePath.split(os.path.sep)[-2] will return \"dogs\"\n","      image = cv2.imread(imagePath)\n","      label = imagePath.split(os.path.sep)[-2]\n","\n","      # check to see if our preprocessors are not None\n","      if self.preprocessors is not None:\n","\t\t\t\t# loop over the preprocessors and apply each to\n","\t\t\t\t# the image\n","        for p in self.preprocessors:\n","          image = p.preprocess(image)\n","\n","\t\t\t# treat our processed image as a \"feature vector\"\n","\t\t\t# by updating the data list followed by the labels\n","      data.append(image)\n","      labels.append(label)\n","   \n","\t\t\t# show an update every `verbose` images\n","      if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n","        logger.info(\"[INFO] processed {}/{}\".format(i + 1,len(imagePaths)))\n","\n","\t\t# return a tuple of the data and labels\n","    return (np.array(data), np.array(labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OC8kcWO07wxB"},"outputs":[],"source":["# grab the list of images that we'll be describing\n","logger.info(\"[INFO] preprocessing images...\")\n","imagePaths = list(paths.list_images(data_dir))\n","\n","# initialize the image preprocessor, load the dataset from disk,\n","# and reshape the data matrix\n","sp = SimplePreprocessor(32, 32)\n","sdl = SimpleDatasetLoader(preprocessors=[sp],logger=logger)\n","(data, labels) = sdl.load(imagePaths, verbose=500)\n","# 32 x 32 x 3 = 3072\n","data = data.reshape((data.shape[0], 3072))\n","\n","# show some information on memory consumption of the images\n","logger.info(\"[INFO] features matrix: {:.1f}MB\".format(data.nbytes / (1024 * 1024)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4utpM8eV8c3T"},"outputs":[],"source":["logger.info(\"Data shape: {}\".format(data.shape))\n","logger.info(\"Label shape: {}\".format(labels.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9KK4Jii8pJe"},"outputs":[],"source":["logger.info(\"Dumping the clean data artifacts to disk\")\n","# Save the feature artifacts using joblib\n","joblib.dump(data, args[\"dataset\"])\n","\n","# Save the target using joblib\n","joblib.dump(labels, args[\"label\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bnnmdpK9BLD2"},"outputs":[],"source":["# clean data artifact\n","artifact = wandb.Artifact(args[\"dataset\"],\n","                          type=\"CLEAN_DATA\",\n","                          description=\"A json file representing the clean and preprocessed data\"\n","                          )\n","\n","logger.info(\"Logging clean data artifact\")\n","artifact.add_file(args[\"dataset\"])\n","run.log_artifact(artifact)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RxuZTgACWVw"},"outputs":[],"source":["# clean label artifact\n","artifact = wandb.Artifact(args[\"label\"],\n","                          type=\"CLEAN_DATA\",\n","                          description=\"A json file representing the clean label\"\n","                          )\n","\n","logger.info(\"Logging clean label artifact\")\n","artifact.add_file(args[\"label\"])\n","run.log_artifact(artifact)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49Ivx0SQCkhT"},"outputs":[],"source":["run.finish()"]},{"cell_type":"code","source":[],"metadata":{"id":"SZpTFgLqsPN7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyNw9kARrdxHr+MpcUV74x34"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}